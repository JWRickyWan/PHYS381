{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first things you learn to do in any experimental physics class is fit a line to data. We can do that pretty easily in python, but the tools we will use have some added flexibility (and therefore complexity).\n",
    "\n",
    "The primary tool we will use is the `curve_fit` function from the `scipy` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function curve_fit in module scipy.optimize.minpack:\n",
      "\n",
      "curve_fit(f, xdata, ydata, p0=None, sigma=None, absolute_sigma=False, check_finite=True, bounds=(-inf, inf), method=None, jac=None, **kwargs)\n",
      "    Use non-linear least squares to fit a function, f, to data.\n",
      "    \n",
      "    Assumes ``ydata = f(xdata, *params) + eps``\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    f : callable\n",
      "        The model function, f(x, ...).  It must take the independent\n",
      "        variable as the first argument and the parameters to fit as\n",
      "        separate remaining arguments.\n",
      "    xdata : An M-length sequence or an (k,M)-shaped array for functions with k predictors\n",
      "        The independent variable where the data is measured.\n",
      "    ydata : M-length sequence\n",
      "        The dependent data --- nominally f(xdata, ...)\n",
      "    p0 : None, scalar, or N-length sequence, optional\n",
      "        Initial guess for the parameters.  If None, then the initial\n",
      "        values will all be 1 (if the number of parameters for the function\n",
      "        can be determined using introspection, otherwise a ValueError\n",
      "        is raised).\n",
      "    sigma : None or M-length sequence or MxM array, optional\n",
      "        Determines the uncertainty in `ydata`. If we define residuals as\n",
      "        ``r = ydata - f(xdata, *popt)``, then the interpretation of `sigma`\n",
      "        depends on its number of dimensions:\n",
      "    \n",
      "            - A 1-d `sigma` should contain values of standard deviations of\n",
      "              errors in `ydata`. In this case, the optimized function is\n",
      "              ``chisq = sum((r / sigma) ** 2)``.\n",
      "    \n",
      "            - A 2-d `sigma` should contain the covariance matrix of\n",
      "              errors in `ydata`. In this case, the optimized function is\n",
      "              ``chisq = r.T @ inv(sigma) @ r``.\n",
      "    \n",
      "              .. versionadded:: 0.19\n",
      "    \n",
      "        None (default) is equivalent of 1-d `sigma` filled with ones.\n",
      "    absolute_sigma : bool, optional\n",
      "        If True, `sigma` is used in an absolute sense and the estimated parameter\n",
      "        covariance `pcov` reflects these absolute values.\n",
      "    \n",
      "        If False, only the relative magnitudes of the `sigma` values matter.\n",
      "        The returned parameter covariance matrix `pcov` is based on scaling\n",
      "        `sigma` by a constant factor. This constant is set by demanding that the\n",
      "        reduced `chisq` for the optimal parameters `popt` when using the\n",
      "        *scaled* `sigma` equals unity. In other words, `sigma` is scaled to\n",
      "        match the sample variance of the residuals after the fit.\n",
      "        Mathematically,\n",
      "        ``pcov(absolute_sigma=False) = pcov(absolute_sigma=True) * chisq(popt)/(M-N)``\n",
      "    check_finite : bool, optional\n",
      "        If True, check that the input arrays do not contain nans of infs,\n",
      "        and raise a ValueError if they do. Setting this parameter to\n",
      "        False may silently produce nonsensical results if the input arrays\n",
      "        do contain nans. Default is True.\n",
      "    bounds : 2-tuple of array_like, optional\n",
      "        Lower and upper bounds on independent variables. Defaults to no bounds.\n",
      "        Each element of the tuple must be either an array with the length equal\n",
      "        to the number of parameters, or a scalar (in which case the bound is\n",
      "        taken to be the same for all parameters.) Use ``np.inf`` with an\n",
      "        appropriate sign to disable bounds on all or some parameters.\n",
      "    \n",
      "        .. versionadded:: 0.17\n",
      "    method : {'lm', 'trf', 'dogbox'}, optional\n",
      "        Method to use for optimization.  See `least_squares` for more details.\n",
      "        Default is 'lm' for unconstrained problems and 'trf' if `bounds` are\n",
      "        provided. The method 'lm' won't work when the number of observations\n",
      "        is less than the number of variables, use 'trf' or 'dogbox' in this\n",
      "        case.\n",
      "    \n",
      "        .. versionadded:: 0.17\n",
      "    jac : callable, string or None, optional\n",
      "        Function with signature ``jac(x, ...)`` which computes the Jacobian\n",
      "        matrix of the model function with respect to parameters as a dense\n",
      "        array_like structure. It will be scaled according to provided `sigma`.\n",
      "        If None (default), the Jacobian will be estimated numerically.\n",
      "        String keywords for 'trf' and 'dogbox' methods can be used to select\n",
      "        a finite difference scheme, see `least_squares`.\n",
      "    \n",
      "        .. versionadded:: 0.18\n",
      "    kwargs\n",
      "        Keyword arguments passed to `leastsq` for ``method='lm'`` or\n",
      "        `least_squares` otherwise.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    popt : array\n",
      "        Optimal values for the parameters so that the sum of the squared\n",
      "        residuals of ``f(xdata, *popt) - ydata`` is minimized\n",
      "    pcov : 2d array\n",
      "        The estimated covariance of popt. The diagonals provide the variance\n",
      "        of the parameter estimate. To compute one standard deviation errors\n",
      "        on the parameters use ``perr = np.sqrt(np.diag(pcov))``.\n",
      "    \n",
      "        How the `sigma` parameter affects the estimated covariance\n",
      "        depends on `absolute_sigma` argument, as described above.\n",
      "    \n",
      "        If the Jacobian matrix at the solution doesn't have a full rank, then\n",
      "        'lm' method returns a matrix filled with ``np.inf``, on the other hand\n",
      "        'trf'  and 'dogbox' methods use Moore-Penrose pseudoinverse to compute\n",
      "        the covariance matrix.\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        if either `ydata` or `xdata` contain NaNs, or if incompatible options\n",
      "        are used.\n",
      "    \n",
      "    RuntimeError\n",
      "        if the least-squares minimization fails.\n",
      "    \n",
      "    OptimizeWarning\n",
      "        if covariance of the parameters can not be estimated.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    least_squares : Minimize the sum of squares of nonlinear functions.\n",
      "    scipy.stats.linregress : Calculate a linear least squares regression for\n",
      "                             two sets of measurements.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    With ``method='lm'``, the algorithm uses the Levenberg-Marquardt algorithm\n",
      "    through `leastsq`. Note that this algorithm can only deal with\n",
      "    unconstrained problems.\n",
      "    \n",
      "    Box constraints can be handled by methods 'trf' and 'dogbox'. Refer to\n",
      "    the docstring of `least_squares` for more information.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> from scipy.optimize import curve_fit\n",
      "    \n",
      "    >>> def func(x, a, b, c):\n",
      "    ...     return a * np.exp(-b * x) + c\n",
      "    \n",
      "    Define the data to be fit with some noise:\n",
      "    \n",
      "    >>> xdata = np.linspace(0, 4, 50)\n",
      "    >>> y = func(xdata, 2.5, 1.3, 0.5)\n",
      "    >>> np.random.seed(1729)\n",
      "    >>> y_noise = 0.2 * np.random.normal(size=xdata.size)\n",
      "    >>> ydata = y + y_noise\n",
      "    >>> plt.plot(xdata, ydata, 'b-', label='data')\n",
      "    \n",
      "    Fit for the parameters a, b, c of the function `func`:\n",
      "    \n",
      "    >>> popt, pcov = curve_fit(func, xdata, ydata)\n",
      "    >>> popt\n",
      "    array([ 2.55423706,  1.35190947,  0.47450618])\n",
      "    >>> plt.plot(xdata, func(xdata, *popt), 'r-',\n",
      "    ...          label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt))\n",
      "    \n",
      "    Constrain the optimization to the region of ``0 <= a <= 3``,\n",
      "    ``0 <= b <= 1`` and ``0 <= c <= 0.5``:\n",
      "    \n",
      "    >>> popt, pcov = curve_fit(func, xdata, ydata, bounds=(0, [3., 1., 0.5]))\n",
      "    >>> popt\n",
      "    array([ 2.43708906,  1.        ,  0.35015434])\n",
      "    >>> plt.plot(xdata, func(xdata, *popt), 'g--',\n",
      "    ...          label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt))\n",
      "    \n",
      "    >>> plt.xlabel('x')\n",
      "    >>> plt.ylabel('y')\n",
      "    >>> plt.legend()\n",
      "    >>> plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(curve_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see that `curve_fit` doesn't just fit lines, but can fit any arbitrary function you can come up with. That's great, but it means you have a little work ahead of you to make the fit work.  Let's try something simple first: a linear fit to linear data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = 4.0\n",
    "intercept = 2.5\n",
    "xdata = np.linspace(0,10,10)\n",
    "ydata = intercept + slope*xdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to fit a linear function, we first have to write a generic linear function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linfunc(x, m, b):\n",
    "    return m*x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then it's as simple as calling `curve_fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4. ,  2.5]), array([[ 0., -0.],\n",
       "        [-0.,  0.]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curve_fit(linfunc, xdata, ydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two things are returned: the parameter values, and the covariance matrix (which roughly speakng is a measure of the uncertainty in those parameter values).  Here, of course, our data exactly fit our model, so the covariance was zero. Let's now add a little noise to make things interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.97576879,  2.44962656]), array([[ 0.0066512 , -0.03325599],\n",
       "        [-0.03325599,  0.23402361]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = np.random.normal(size=10)\n",
    "curve_fit(linfunc, xdata, ydata+noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, it's hard to understand what's going on without plotting.  Let's do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXUQkSajQRUSShApdRCRJqNBFRJLE/wNVh7ZbMNxUJQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f38a95f7668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "popt, pcov = curve_fit(linfunc, xdata, ydata+noise)\n",
    "plt.errorbar(xdata, ydata+noise, yerr=1.0, linestyle=\"\",label=\"data\")\n",
    "plt.plot(xdata, linfunc(xdata, *popt), label=\"fit\")\n",
    "plt.legend()\n",
    "title = plt.title(\"fit to data plus noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.97576879  2.44962656]\n"
     ]
    }
   ],
   "source": [
    "print(popt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0 2.5\n"
     ]
    }
   ],
   "source": [
    "print(slope, intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An exercise\n",
    "\n",
    "Here are four datasets. produce a linear fit (and a plot like that above) for each. When you are done, make a table with the fitting parameters for each.  This dataset is known as \"Anscombe's quarted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ans1 = pd.read_pickle(\"../data/ans1.pkl\")\n",
    "ans2 = pd.read_pickle(\"../data/ans2.pkl\")\n",
    "ans3 = pd.read_pickle(\"../data/ans3.pkl\")\n",
    "ans4 = pd.read_pickle(\"../data/ans4.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
